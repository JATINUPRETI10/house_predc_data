{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JATINUPRETI10/house_predc_data/blob/main/ADV_house_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqvLUOHe4a0T"
      },
      "source": [
        "# loading liabraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JgcBKQHVPjLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kii2TP0K4Ojs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from pandas.api.types import CategoricalDtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQWhhS8l4YYM"
      },
      "source": [
        "# loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "odIGv_i448pw"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data=pd.read_csv(\"https://raw.githubusercontent.com/JATINUPRETI10/house_predc_data/refs/heads/main/train.md\")\n",
        "test_data=pd.read_csv(\"https://raw.githubusercontent.com/JATINUPRETI10/house_predc_data/refs/heads/main/test.md\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ0Lt-Ic9L50"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LPEf4JHbL-y"
      },
      "outputs": [],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PIeRJxvbOnM"
      },
      "outputs": [],
      "source": [
        "#head allow us to see top 5 rows of content\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJTgzrg5bXd2"
      },
      "outputs": [],
      "source": [
        "#head allow us to see top 5 rows of content\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6j6fUpIbcX9"
      },
      "outputs": [],
      "source": [
        "#to view all the columns of a table all together use option method(),none tell us we have to se all col\n",
        "pd.set_option('display.max_columns',None)\n",
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svhEK2rhb7Sd"
      },
      "outputs": [],
      "source": [
        "#to view all the row of a table all together use option method(),none tell us we have to se all col\n",
        "pd.set_option('display.max_rows',None)\n",
        "test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yordC9kM9kF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uLZk6Macqn_"
      },
      "outputs": [],
      "source": [
        "#ALL THE COL THAT WILL BE USEFULL IN MAKING COL\n",
        "#mszoning\n",
        "#lotarea\n",
        "#street\n",
        "#utilities\n",
        "#neighbourhood\n",
        "#BldgType: Type of dwelling\n",
        "#HouseStyle: Style of dwelling\n",
        "#yearbuild\n",
        "#foundation\n",
        "#heating\n",
        "#heating_qc\n",
        "#central_air\n",
        "#electrical\n",
        "#kitchen\n",
        "#garage\n",
        "#fence\n",
        "#SaleCondition: Condition of sale#SaleType: Type of sale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P9s4xbx1nen"
      },
      "source": [
        "# data integration(adding training and testing data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shKr77Q2u_QI"
      },
      "outputs": [],
      "source": [
        "data=pd.concat([train_data,test_data])\n",
        "data.shape\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxIJBi5J19E-"
      },
      "outputs": [],
      "source": [
        "#now get info of u r data\n",
        "data.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyp2w0Dz2gFa"
      },
      "outputs": [],
      "source": [
        "#remove all the column having many null values\n",
        "#masvnrtype\n",
        "#poolqc\n",
        "#fence\n",
        "#fireplace\n",
        "#miscfeature\n",
        "#alley"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFPCiyMw30PZ"
      },
      "outputs": [],
      "source": [
        "int_feature=data.select_dtypes(include=['int64']).columns\n",
        "#int_feature.shape[0]\n",
        "int_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztnDKT8O4wFQ"
      },
      "outputs": [],
      "source": [
        "float_feature=data.select_dtypes(include=['float64']).columns\n",
        "#float_feature.shape[0]\n",
        "float_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZUfWim-4G2u"
      },
      "outputs": [],
      "source": [
        "obj_feature=data.select_dtypes(include=['object']).columns\n",
        "#obj_feature.shape[0]\n",
        "obj_feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj4D8Js5N6KN"
      },
      "source": [
        "# get statistical info of your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wv7aSg25cvD"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTM3P7zZNJpI"
      },
      "source": [
        "# handling missing value\n",
        "visualsing missing/null value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i30TsdU7NXZm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wd7bCInXzhn"
      },
      "outputs": [],
      "source": [
        "# delete all the col with higher perc except sales price\n",
        "null_percentage = data.isnull().sum()/data.shape[0] *100\n",
        "null_percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR2_UQ4QdlSW"
      },
      "source": [
        "# Drop feature/column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHCRbepnYRhY"
      },
      "outputs": [],
      "source": [
        "missingvalue_50=null_percentage[null_percentage>50]\n",
        "missingvalue_50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDXlkTfxejj2"
      },
      "source": [
        "since alley,masvnr,poolqc etc have higher null value percentage but still it still cant be removed because the null value are holding values\n",
        "\n",
        "\n",
        "ex-poolqc have subvalues good ,bad and no pool cond so all no pool cond are lying inside the null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cRmR7QeeDGr"
      },
      "outputs": [],
      "source": [
        "missingvalue_20=null_percentage[(null_percentage>20)&(null_percentage<50)]\n",
        "missingvalue_20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCKYTZ4-eXNK"
      },
      "outputs": [],
      "source": [
        "missingvalue_20=null_percentage[(null_percentage>5)&(null_percentage<20)]\n",
        "missingvalue_20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7U8I74AjcMa"
      },
      "source": [
        "# missing value implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ-Hpg_xeeZM"
      },
      "outputs": [],
      "source": [
        "missing_value_feature=null_percentage[(null_percentage>0)]\n",
        "missing_value_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "454e0Sg2kX6y"
      },
      "outputs": [],
      "source": [
        "missing_value_feature[missing_value_feature.keys().isin(obj_feature) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_75nDDwlree"
      },
      "outputs": [],
      "source": [
        "missing_value_feature[missing_value_feature.keys().isin(int_feature) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tOD66GNmEmk"
      },
      "outputs": [],
      "source": [
        "missing_value_feature[missing_value_feature.keys().isin(float_feature) ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We-ag93LmuzO"
      },
      "source": [
        "# handling ms zoning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awdqkf2zmM6R"
      },
      "outputs": [],
      "source": [
        "data['MSZoning'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7bf93c6m6kh"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data[\"MSZoning\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn5DCw05nhzh"
      },
      "source": [
        "# now we will be using mode values in missing value of ms zoining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tjFMiAFn3k4"
      },
      "outputs": [],
      "source": [
        "data_copy=data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGZQHLWPnRRC"
      },
      "outputs": [],
      "source": [
        "ms_mode=data['MSZoning'].mode()[0]\n",
        "data_copy[\"MSZoning\"].replace(np.nan,ms_mode,inplace=True)\n",
        "data_copy[\"MSZoning\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf3NBnHJo1pr"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data_copy[\"MSZoning\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCzB5euoo6ZF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaFm4bqrptGj"
      },
      "source": [
        "# handling alley"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1IR0qDypyTJ"
      },
      "outputs": [],
      "source": [
        "data_copy['Alley'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeYD1tdhAdCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAm2n7G0p304"
      },
      "outputs": [],
      "source": [
        "alley_const='NA'\n",
        "data_copy[\"Alley\"].replace(np.nan,'NA',inplace=True)\n",
        "data_copy[\"Alley\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX2Q6US2sWic"
      },
      "source": [
        "# load frontage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RzXnTjCqb9P"
      },
      "outputs": [],
      "source": [
        "def boxhisplot(data,figsize=(16,5)):\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.subplot(121)\n",
        "  plt.boxplot(data)\n",
        "  plt.subplot(122)\n",
        "  sns.distplot(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhQ9g4lDtH_3"
      },
      "outputs": [],
      "source": [
        "boxhisplot(data_copy['LotFrontage'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_2PQOSItdNf"
      },
      "outputs": [],
      "source": [
        "load_mean=data['LotFrontage'].mode()[0]\n",
        "data_copy[\"LotFrontage\"].replace(np.nan,load_mean,inplace=True)\n",
        "data_copy[\"LotFrontage\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpcWxRn0ub8s"
      },
      "source": [
        "# utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeWaKUGZt8n2"
      },
      "outputs": [],
      "source": [
        "utilities_mode=data['Utilities'].mode()[0]\n",
        "data_copy[\"Utilities\"].replace(np.nan,utilities_mode,inplace=True)\n",
        "data_copy[\"Utilities\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGL6avdVutOb"
      },
      "outputs": [],
      "source": [
        "ext1_mode=data['Exterior1st'].mode()[0]\n",
        "data_copy[\"Exterior1st\"].replace(np.nan,ext1_mode,inplace=True)\n",
        "data_copy[\"Exterior1st\"].isnull().sum()\n",
        "ext2_mode=data['Exterior2nd'].mode()[0]\n",
        "data_copy[\"Exterior2nd\"].replace(np.nan,ext2_mode,inplace=True)\n",
        "data_copy[\"Exterior2nd\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk3CweaRvsSZ"
      },
      "outputs": [],
      "source": [
        "mass_vnr_type=data['MasVnrType'].mode()[0]\n",
        "data_copy[\"MasVnrType\"].replace(np.nan,mass_vnr_type,inplace=True)\n",
        "data_copy['MasVnrType'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvmex_GFAjrK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWn_hhmomJwq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf0eU2wimQuF"
      },
      "outputs": [],
      "source": [
        "cat_bsmt_feat=[\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\"]\n",
        "num_bsmt_feat=[\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"BsmtFullBath\",\"BsmtHalfBath\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UoLl1NomdZD"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(data[cat_bsmt_feat].isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GIdhmTKmz3z"
      },
      "outputs": [],
      "source": [
        "for feat in cat_bsmt_feat:\n",
        "  print(data[feat].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdSiBu1AnC_-"
      },
      "outputs": [],
      "source": [
        "bsmt_const=\"NA\"\n",
        "for feat in cat_bsmt_feat:\n",
        "  data_copy[feat].replace(np.nan,bsmt_const,inplace=True)\n",
        "  data_copy[feat].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv7G2T2InUjV"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(data_copy[num_bsmt_feat].isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0dwtmUToFWv"
      },
      "outputs": [],
      "source": [
        "data_bsmt=data[cat_bsmt_feat+num_bsmt_feat]\n",
        "data_bsmt[data_bsmt.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-OK-TdFoksO"
      },
      "outputs": [],
      "source": [
        "bsmt_num=0\n",
        "for feat in num_bsmt_feat:\n",
        "  data_copy[feat].replace(np.nan,bsmt_num,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI7jYe1Oo3H5"
      },
      "outputs": [],
      "source": [
        "  data_copy[feat].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9KLRlqMpCOI"
      },
      "source": [
        "## handling elec and kitchen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoWAfeDzo9ZO"
      },
      "outputs": [],
      "source": [
        "data[\"Electrical\"].value_counts()\n",
        "data[\"KitchenQual\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OChZl5HVqUXI"
      },
      "outputs": [],
      "source": [
        "data_ekk=data[[\"Electrical\",\"KitchenQual\",\"KitchenAbvGr\"]]\n",
        "data_ekk[data_ekk.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5gSSvjLqWEj"
      },
      "outputs": [],
      "source": [
        "elec_mode=data[\"Electrical\"].mode()[0]\n",
        "data_copy[\"Electrical\"].replace(np.nan,elec_mode,inplace=True)\n",
        "data_copy[\"Electrical\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-XYS09GqVXQ"
      },
      "outputs": [],
      "source": [
        "kitchen_mode=data[\"KitchenQual\"].mode()[0]\n",
        "data_copy[\"KitchenQual\"].replace(np.nan,kitchen_mode,inplace=True)\n",
        "data_copy[\"KitchenQual\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aUFT_iwreg9"
      },
      "source": [
        "# handling other cat value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KKy3ZvqreK5"
      },
      "outputs": [],
      "source": [
        "func_mode=data[\"Functional\"].mode()[0]\n",
        "data_copy[\"Functional\"].replace(np.nan,func_mode,inplace=True)\n",
        "data_copy[\"Functional\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is_aWJ55pm4D"
      },
      "outputs": [],
      "source": [
        "sales_type_mode=data[\"SaleType\"].mode()[0]\n",
        "data_copy[\"SaleType\"].replace(np.nan,sales_type_mode,inplace=True)\n",
        "data_copy[\"SaleType\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2yZDn1EsUx2"
      },
      "outputs": [],
      "source": [
        "fire_qc_mode=data[\"FireplaceQu\"].mode()[0]\n",
        "data_copy[\"FireplaceQu\"].replace(np.nan,fire_qc_mode,inplace=True)\n",
        "data_copy[\"FireplaceQu\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHOmsP6ZAxUI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wBQYP7KsbvK"
      },
      "outputs": [],
      "source": [
        "pool_qc_mode=data[\"PoolQC\"].mode()[0]\n",
        "data_copy[\"PoolQC\"].replace(np.nan,pool_qc_mode,inplace=True)\n",
        "data_copy[\"PoolQC\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL5900HgsbK4"
      },
      "outputs": [],
      "source": [
        "misc_feat_mode=data[\"MiscFeature\"].mode()[0]\n",
        "data_copy[\"MiscFeature\"].replace(np.nan,misc_feat_mode,inplace=True)\n",
        "data_copy[\"MiscFeature\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evdy69Aqsy7C"
      },
      "source": [
        "# handling garage value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yni16F3Bs6Ei"
      },
      "outputs": [],
      "source": [
        "num_garage_feat=[\"GarageYrBlt\",\"GarageArea\",\"GarageCars\"]\n",
        "cat_garage_feat=[\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\"]\n",
        "data_garage=data[num_garage_feat+cat_garage_feat]\n",
        "data_garage[data_garage.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL-cgnXIs6Bz"
      },
      "outputs": [],
      "source": [
        "garag_cont=0\n",
        "for feat in cat_garage_feat:\n",
        "  data_copy[feat].replace(np.nan,garag_cont,inplace=True)\n",
        "  data_copy[feat].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ree108AEs5_Y"
      },
      "outputs": [],
      "source": [
        "data_copy.isnull().any(axis=1).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wekSwkJPs58X"
      },
      "outputs": [],
      "source": [
        "data_copy['BsmtCond'] = data_copy['BsmtCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJBmsn7es55o"
      },
      "outputs": [],
      "source": [
        "data_copy['BsmtCond'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID4GHpRUs52l"
      },
      "outputs": [],
      "source": [
        "data_copy['BsmtExposure'] = data_copy['BsmtExposure'].astype(CategoricalDtype(categories=['NA', 'Mn', 'Av', 'Gd'], ordered = True)).cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUohZJ7Ns5xW"
      },
      "outputs": [],
      "source": [
        "data_copy['BsmtExposure'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShEGMo4fs5o-"
      },
      "outputs": [],
      "source": [
        "data_copy['BsmtFinType1'] = data_copy['BsmtFinType1'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
        "data_copy['BsmtFinType2'] = data_copy['BsmtFinType2'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
        "data_copy['BsmtQual'] = data_copy['BsmtQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['ExterQual'] = data_copy['ExterQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['ExterCond'] = data_copy['ExterCond'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['Functional'] = data_copy['Functional'].astype(CategoricalDtype(categories=['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod','Min2','Min1', 'Typ'], ordered = True)).cat.codes\n",
        "data_copy['GarageCond'] = data_copy['GarageCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['GarageQual'] = data_copy['GarageQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['GarageFinish'] = data_copy['GarageFinish'].astype(CategoricalDtype(categories=['NA', 'Unf', 'RFn', 'Fin'], ordered = True)).cat.codes\n",
        "data_copy['HeatingQC'] = data_copy['HeatingQC'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['KitchenQual'] = data_copy['KitchenQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
        "data_copy['PavedDrive'] = data_copy['PavedDrive'].astype(CategoricalDtype(categories=['N', 'P', 'Y'], ordered = True)).cat.codes\n",
        "data_copy['Utilities'] = data_copy['Utilities'].astype(CategoricalDtype(categories=['ELO', 'NASeWa', 'NASeWr', 'AllPub'], ordered = True)).cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKiF46R4s5fG"
      },
      "outputs": [],
      "source": [
        "data_copy['Utilities'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SJydSo-y1omU"
      },
      "outputs": [],
      "source": [
        "data_copy.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2QLr0wtg153l"
      },
      "outputs": [],
      "source": [
        "copy_obj=data_copy.copy()\n",
        "obj_feat=data_copy.select_dtypes(include=\"object\").columns.tolist()\n",
        "print(len(data_copy))\n",
        "print(\"/n\",data_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEhxJONt4AOX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "copy_obj=data_copy.copy()\n",
        "# Get the list of object type columns before applying get_dummies\n",
        "obj_feat=data_copy.select_dtypes(include=\"object\").columns.tolist()\n",
        "print(len(data_copy))\n",
        "print(\"/n\",data_copy)\n",
        "\n",
        "# Apply get_dummies to create new columns for categorical features\n",
        "copy_obj=pd.get_dummies(copy_obj,columns=obj_feat,prefix=obj_feat,drop_first=True)\n",
        "\n",
        "# Access the newly created columns using their modified names\n",
        "# Example: If 'MSZoning' was an original column, it might be now 'MSZoning_FV', 'MSZoning_RH', etc.\n",
        "# You can access these using copy_obj[['MSZoning_FV', 'MSZoning_RH', ...]].head(2)\n",
        "\n",
        "# If you still need to access the original columns in 'data_copy',\n",
        "# they are still available in that DataFrame.\n",
        "data_copy[obj_feat].head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4dmdlTlNtbM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Continue with further processing as needed.  The provided code has already\n",
        "# handled a significant portion of data cleaning and preprocessing.\n",
        "# Example: Feature scaling, model training, or further EDA.\n",
        "\n",
        "# Example: Scaling numerical features using MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "numerical_features = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', # Add other numerical features\n",
        "                      'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
        "                      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
        "                      '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
        "                      'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
        "                      'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
        "                      'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
        "                      'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
        "                      'MiscVal', 'MoSold', 'YrSold']\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "copy_obj[numerical_features] = scaler.fit_transform(copy_obj[numerical_features])\n",
        "\n",
        "\n",
        "# Example: Splitting the data back into training and testing sets\n",
        "train_len = len(train_data)\n",
        "X_train = copy_obj[:train_len]\n",
        "X_test = copy_obj[train_len:]\n",
        "y_train = X_train[\"SalePrice\"]\n",
        "\n",
        "X_train.drop('SalePrice',axis=1,inplace = True)\n",
        "X_test.drop('SalePrice',axis=1,inplace=True)\n",
        "\n",
        "# ... (rest of your model training and evaluation code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTprPdhv5Df9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Initialize the imputer to replace NaN with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit and transform the imputer on the training data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the trained imputer\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "\n",
        "# Initialize and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_imputed, y_train) # Use imputed training data\n",
        "\n",
        "# Make predictions on the training set\n",
        "y_pred_train = model.predict(X_train_imputed) # Use imputed training data\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(\"Training Set Evaluation:\")\n",
        "print(f\"Mean Squared Error: {mse_train}\")\n",
        "print(f\"R-squared: {r2_train}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test = model.predict(X_test_imputed) # Use imputed test data\n",
        "\n",
        "\n",
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': y_pred_test})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The second call to pd.get_dummies using the original obj_feature is incorrect\n",
        "# because the object columns were already encoded and removed in the previous step.\n",
        "# copy_obj=pd.get_dummies(copy_obj,columns=obj_feature,prefix=obj_feature,drop_first=True)\n",
        "\n",
        "# Continue with the rest of the processing steps after the correct get_dummies call in cell 94.\n",
        "\n",
        "\n",
        "# Continue with further processing as needed.  The provided code has already\n",
        "# handled a significant portion of data cleaning and preprocessing.\n",
        "# Example: Feature scaling, model training, or further EDA.\n",
        "\n",
        "# Example: Scaling numerical features using MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "numerical_features = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', # Add other numerical features\n",
        "                      'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
        "                      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
        "                      '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
        "                      'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
        "                      'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
        "                      'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
        "                      'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
        "                      'MiscVal', 'MoSold', 'YrSold']\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "copy_obj[numerical_features] = scaler.fit_transform(copy_obj[numerical_features])\n",
        "\n",
        "\n",
        "# Example: Splitting the data back into training and testing sets\n",
        "train_len = len(train_data)\n",
        "X_train = copy_obj[:train_len]\n",
        "X_test = copy_obj[train_len:]\n",
        "y_train = X_train[\"SalePrice\"]\n",
        "\n",
        "X_train.drop('SalePrice',axis=1,inplace = True)\n",
        "X_test.drop('SalePrice',axis=1,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Initialize the imputer to replace NaN with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit and transform the imputer on the training data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the trained imputer\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "\n",
        "# Initialize and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_imputed, y_train) # Use imputed training data\n",
        "\n",
        "# Make predictions on the training set\n",
        "y_pred_train = model.predict(X_train_imputed) # Use imputed training data\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(\"Training Set Evaluation:\")\n",
        "print(f\"Mean Squared Error: {mse_train}\")\n",
        "print(f\"R-squared: {r2_train}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test = model.predict(X_test_imputed) # Use imputed test data\n",
        "\n",
        "\n",
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': y_pred_test})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "\n",
        "# Instead of Linear Regression, try more sophisticated models like RandomForestRegressor or GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Example using RandomForestRegressor:\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42) # Tune n_estimators and other hyperparameters\n",
        "model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# ... (rest of your prediction and evaluation code)\n",
        "\n",
        "# Example using GradientBoostingRegressor\n",
        "# model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42) # Tune hyperparameters\n",
        "# model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# ... (rest of your prediction and evaluation code)\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "# Use GridSearchCV or RandomizedSearchCV to find optimal hyperparameters for your chosen model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Example using GridSearchCV with RandomForestRegressor\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train_imputed, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Use the best model for predictions\n",
        "\n",
        "y_pred_train = best_model.predict(X_train_imputed)\n",
        "y_pred_test = best_model.predict(X_test_imputed)\n",
        "\n",
        "\n",
        "# Feature Engineering: Create new features from existing ones\n",
        "# Example: Combine existing features or create interaction terms\n",
        "# copy_obj['TotalSF'] = copy_obj['TotalBsmtSF'] + copy_obj['1stFlrSF'] + copy_obj['2ndFlrSF']\n",
        "\n",
        "# ... (Add other relevant feature engineering)\n",
        "\n",
        "# Evaluate model performance more comprehensively\n",
        "# Use cross-validation techniques like cross_val_score to obtain more robust performance estimates\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(best_model, X_train_imputed, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-validation scores:\", -scores) # Negative MSE scores are returned, hence the negation"
      ],
      "metadata": {
        "id": "7yqccDs_vd11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Train with best model\n",
        "best_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = best_model.predict(X_test_imputed)\n",
        "\n",
        "# Save predictions\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': y_pred_test})\n",
        "submission.to_csv('submission_best_model.csv', index=False)\n"
      ],
      "metadata": {
        "id": "bK3TWbJq0zMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_model, \"best_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(X_train.columns.tolist(), \"columns.pkl\")\n"
      ],
      "metadata": {
        "id": "3Obi7JnJ6R6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8QrAQBYR7Cs8",
        "outputId": "5fbd2d02-089a-4e58-8d2e-3e038d11f470"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First check what neighborhoods your model knows about\n",
        "neighborhood_cols = [col for col in columns if col.startswith(\"Neighborhood_\")]\n",
        "neighborhoods = [col.split(\"_\")[1] for col in neighborhood_cols]\n",
        "print(neighborhoods)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccDWHBA9smPV",
        "outputId": "bedc04c0-029a-495e-c25c-8d0be29d98f4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Blueste', 'BrDale', 'BrkSide', 'ClearCr', 'CollgCr', 'Crawfor', 'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV', 'Mitchel', 'NAmes', 'NPkVill', 'NWAmes', 'NoRidge', 'NridgHt', 'OldTown', 'SWISU', 'Sawyer', 'SawyerW', 'Somerst', 'StoneBr', 'Timber', 'Veenker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load your saved models and data\n",
        "model = joblib.load(\"best_model.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "columns = joblib.load(\"columns.pkl\")\n",
        "\n",
        "def predict_price(\n",
        "    OverallQual=6,\n",
        "    GrLivArea=1500,\n",
        "    GarageArea=480,\n",
        "    TotalBsmtSF=1000,\n",
        "    YearBuilt=2000,\n",
        "    FullBath=2,\n",
        "\n",
        "):\n",
        "    try:\n",
        "        # 1. Create base dictionary with numerical features\n",
        "        input_data = {\n",
        "            \"OverallQual\": OverallQual,\n",
        "            \"GrLivArea\": GrLivArea,\n",
        "            \"GarageArea\": GarageArea,\n",
        "            \"TotalBsmtSF\": TotalBsmtSF,\n",
        "            \"YearBuilt\": YearBuilt,\n",
        "            \"FullBath\": FullBath\n",
        "        }\n",
        "\n",
        "        # 2. Create DataFrame with ALL expected columns (initialized to 0)\n",
        "        df = pd.DataFrame(columns=columns)\n",
        "        df.loc[0] = 0\n",
        "\n",
        "        # 3. Fill numerical features\n",
        "        for col in input_data:\n",
        "            if col in df.columns:\n",
        "                df[col] = input_data[col]\n",
        "\n",
        "\n",
        "\n",
        "        # 6. Scale and predict\n",
        "        df_scaled = scaler.transform(df)\n",
        "        prediction = model.predict(df_scaled)[0]\n",
        "\n",
        "        return f\" Predicted Price: ${prediction:,.2f}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"ERROR\"\n",
        "\n",
        "# Create Gradio interface with categorical options\n",
        "demo = gr.Interface(\n",
        "    fn=predict_price,\n",
        "    inputs=[\n",
        "        gr.Slider(1, 10, step=1, value=6, label=\"Overall Quality\"),\n",
        "        gr.Number(value=1500, label=\"Living Area (sqft)\"),\n",
        "        gr.Number(value=480, label=\"Garage Area (sqft)\"),\n",
        "        gr.Number(value=1000, label=\"Basement Area (sqft)\"),\n",
        "        gr.Slider(1870, 2023, step=1, value=2000, label=\"Year Built\"),\n",
        "        gr.Slider(0, 4, step=1, value=2, label=\"Full Baths\"),\n",
        "\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\" Advanced House Price Predictor\",\n",
        "    examples=[\n",
        "        [6, 1500, 480, 1000, 2000, 2],\n",
        "        [8, 2500, 800, 1500, 2015, 3]\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "O9Y908oV7Dpk",
        "outputId": "d5983f77-64cf-4f6d-938e-7e00c1fe9723"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://33e293ed3bb0b0faef.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://33e293ed3bb0b0faef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze | grep -E \"gradio|pandas|scikit-learn|numpy|joblib\" > requirements.txt"
      ],
      "metadata": {
        "id": "MBoyEOY1f1-2"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9SkAvcMvf-x2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMouAxWg0V5yZed5alF0M54",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}